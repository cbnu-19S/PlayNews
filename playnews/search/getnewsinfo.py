# ì•Œê³ ë¦¬ì¦˜
# 1. APIë‘ í†µì‹ í•´ì„œ naver linkë§Œ ê°€ì ¸ì˜¤ê¸° -> ì™„ë£Œ??!
# 2. ë°ì´í„°í…Œì´ë¸”ì— ë§ì¶°ì„œ ë°ì´í„° ìŠ¤í¬ë˜í•‘í•˜ê¸°!

# https://velog.io/@lybin10/%EB%84%A4%EC%9D%B4%EB%B2%84-API%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%9C-%ED%81%AC%EB%A1%A4%EB%A7%81

# ì¶”ê°€ë¡œ ìƒì˜í•  ë¶€ë¶„!
# í‚¤ì›Œë“œ -> ì–¸ë‹ˆê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ê¸° ìœ„í•´ ë”°ë¡œ ì½”ë“œ ì‘ì„±í•˜ë©´ ë  ë“¯í•¨
# ê¸°ì‚¬ ì¤‘ê°„ì¤‘ê°„ í”„ë ˆì„ì›Œí¬ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨ëœ ì½”ë“œê°€ ì‚½ì…ë˜ì–´ ìˆì–´ì„œ í…ìŠ¤íŠ¸ ê·¸ë˜ë„ ê°€ì ¸ì™€ì•¼ í•  ê²ƒ ê°™ìŒ
# br íƒœê·¸ë§Œ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ë©´ ë  ë“¯í•¨
# DB ì†ì„± ì¤‘ 'ì „í™”' ì‚­ì œí•˜ê¸° (ê¸°ì‚¬ì— ìˆëŠ” ê±¸ ë³¸ ì ì´ ì—†ìŒ...), ê¸°ìì´ë¦„ì´ë‘ ë©”ì¼ ê°™ì´ í‘œì‹œë˜ë„ë¡ ë°”ê¾¸ê¸°!

# --------------------------------------------------------------------------
# URL(ëŒ€ë¶€ë¶„ HTTP)ì„ ì—¬ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import urllib.request
import json
import datetime
from bs4 import BeautifulSoup, Comment
from requests import get
import pickle

# ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ ID/ë¹„ë°€í‚¤
client_id = 'IOUzsco6f11Y2fdiKzsh'
client_secret = 'pmfbtWIWhX'

# Api URL
news_api = "https://openapi.naver.com/v1/search/news.json"
url_news = "https://openapi.naver.com/v1/search"

# [CODE 1] - ì„œë²„ì— ìš”ì²­í•´ ë°›ì€ json íŒŒì¼ì„ pythonì˜ str íƒ€ì…ìœ¼ë¡œ ë³€í™˜ì‹œì¼œ ë°˜í™˜
def getRequestUrl(api_url):
    # class urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None)
    req = urllib.request.Request(api_url)

    # í—¤ë” ê°ì²´ë¥¼ ì´ìš©í•´ í—¤ë”ì— í´ë¼ì´ì–¸íŠ¸ ì•„ì´ë””, ë¹„ë°€í‚¤ ì¶”ê°€
    req.add_header("X-Naver-Client-Id", client_id)
    req.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        response = urllib.request.urlopen(req)
        # 200 = OK, news_api ì ‘ì† ì„±ê³µ
        if response.getcode() == 200:
            print(f"{datetime.datetime.now()}: {api_url} Request Success")
            return response.read().decode('utf-8')
    
    # except ì˜ˆì™¸ ì²˜ë¦¬ as ì˜¤ë¥˜ ë©”ì‹œì§€ ë³€ìˆ˜
    except Exception as e :
        print(e)
        print("[%s] Error for URL : %s" % (datetime.datetime.now(), api_url))
        return None

# [CODE 2] 
def getNaverSearch(type, srcText, start, display):
    type = "/%s.json" % type

    # APIë¥¼ í˜¸ì¶œí•  ë•ŒëŠ” ê²€ìƒ‰ì–´ì™€ ê²€ìƒ‰ ì¡°ê±´ì„ ì¿¼ë¦¬ ìŠ¤íŠ¸ë§(Query String) í˜•ì‹ì˜ ë°ì´í„°ë¡œ ì „ë‹¬

    # urllib.parse.quote(string, safe='/', encoding=None, errors=None)
    parameters = "?query=%s&start=%s&display=%s" % (urllib.parse.quote(srcText), start, display)

    url = url_news + type + parameters
    responseDecode = getRequestUrl(url)     #[CODE 1]

    # try:
    if(responseDecode == None):
        return None

    else:
        return json.loads(responseDecode) # JSON ë¬¸ì„œë¥¼ í¬í•¨í•˜ëŠ” str -> íŒŒì´ì¬ ê°ì²´ë¡œ ë³€í™˜(ì—¬ê¸°ì„œëŠ” dict, ì–´ë–¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ë˜ëŠ”ì§€ëŠ” json.loads() ë³€í™˜í‘œ ì°¸ê³ )
    
#[CODE 3] - str êµ¬ë¶„í•´ì„œ ì €ì¥í•˜ê¸°
def getPostData(post, jsonResult, cnt):
    link = post['link'] #ë„¤ì´ë²„ ë‰´ìŠ¤ URL
    title = post['title'] # ê¸°ì‚¬ ì œëª©
    jsonResult.append({'cnt':cnt, 'title':title, 'link':link})
    return


# find_all() -> list
# [CODE 4] - parse html
def getNewsData(post, DataResult):
    # ê¸°ì¡´ ì •ë³´ ë„£ê¸°
    cnt = post['cnt']
    title = post['title']
    link = post['link']
    
    # bs4 ì´ìš©í•˜ì—¬ ìŠ¤í¬ë˜í•‘í•˜ëŠ” ì½”ë“œ ğŸ‘‡ headersì— ê¼­ ì ‘ì† ì •ë³´ ë„£ì–´ ì¤˜ì•¼ í•¨
    response = get(post['link'], headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'})
    soup = BeautifulSoup(response.text, "html.parser")
    
    # ê¸°ì‚¬ ì‘ì„± ë‚ ì§œ [Date]
    date_first = soup.find('span', class_='media_end_head_info_datestamp_time _ARTICLE_DATE_TIME')
    date_mod = soup.find('span', class_='media_end_head_info_datestamp_time _ARTICLE_MODIFY_DATE_TIME _ARTICLE_DATE_TIME')
    
    # ì‹ ë¬¸ì‚¬ [newspaper]
    newspaper = soup.find('img', class_='media_end_head_top_logo_img light_type', alt = True)
    newspaper = newspaper['alt']
    
    # ê¸°ì ì´ë¦„ [writer]
    writer = soup.find('em', class_="media_end_head_journalist_name")
    if writer is None:
        writer = soup.find('span', class_="byline_s")

    # ìˆ˜ì •
    body = soup.find('div', class_="go_trans _article_content")
    
    # ì•Œê³ ë¦¬ì¦˜ 
    # ë³¸ë¬¸ forë¬¸ì„ ëŒë©´ì„œ img íƒœê·¸ëŠ” ì´ë¯¸ì§€ì— ë”°ë¡œ ì €ì¥, í…ìŠ¤íŠ¸ëŠ” í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì— ë”°ë¡œ ì €ì¥
    # ì´ë¯¸ì§€ê°€ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ ë¬¸ì¥ë“¤ì„ ë¶™ì—¬ì„œ ì €ì¥í•˜ë‹¤ê°€ ì´ë¯¸ì§€ê°€ ë‚˜ì˜¤ë©´ ë°”ë¡œ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥, ê·¸ë¦¬ê³  ë‹¤ìŒ í…ìŠ¤íŠ¸ë“¤ì€ ë‹¤ìŒ ì¸ë±ìŠ¤ì— ë„£ëŠ”ë‹¤.
    # ì´ë¯¸ì§€ê°€ ë‚˜ì˜¤ë©´ img ë§í¬ì™€ ì„¤ëª…ì„ ë”°ë¡œ ì €ì¥í•œë‹¤. (íƒœê·¸ ì‚­ì œí•˜ê³  ë„£ì–´ë²„ë¦¬ê¸°)
    context = [] # ë³¸ë¬¸ ë‚´ìš©
    img_link = [] # ì´ë¯¸ì§€ ë§í¬
    img_alt = [] # ì´ë¯¸ì§€ ì„¤ëª…
    content = ''
    
    for i in body:
        if (i.find('img') == -1) or(i.find('img') == None) and (i.find('em') == -1) or(i.find('em') == None):
            content += i.text
        else:
            if i.find('img') is not None:
                img = i.find('img')
                img_link.append(img['data-src'])
                alt = i.find('em', class_ = 'img_desc')
                img_alt.append(alt.text)
                context.append(content)
                content = ''
            else:
                continue
                
    if date_mod is not None and writer is not None:
        DataResult.append({'cnt':cnt, 'title' : title, 'link' : link , 'date_first' : date_first.string, 'date_mod' : date_mod.string, 'newspaper':newspaper, 'writer':writer.string, 'context':context, 'img':
        {
            'img_link':img_link,
            'img_alt':img_alt
        }
            })
    elif date_mod is None and writer is not None:
         DataResult.append({'cnt':cnt, 'title' : title, 'link' : link , 'date_first' : date_first.string, 'date_mod' : None, 'newspaper':newspaper, 'writer':writer.string, 'context':context, 'img':
        {
            'img_link':img_link,
            'img_alt':img_alt
        }
            })
    elif date_mod is not None and writer is None:
         DataResult.append({'cnt':cnt, 'title' : title, 'link' : link , 'date_first' : date_first.string, 'date_mod' : date_mod.string, 'newspaper':newspaper, 'writer':None, 'context':context, 'img':
        {
            'img_link':img_link,
            'img_alt':img_alt
        }
            })
    else:
        DataResult.append({'cnt':cnt, 'title' : title, 'link' : link , 'date_first' : date_first.string, 'date_mod' : None, 'newspaper':newspaper, 'writer':None, 'context':context, 'img':
        {
            'img_link':img_link,
            'img_alt':img_alt
        }
            })
        
    print(DataResult)
    return

#[CODE 0] - main í•¨ìˆ˜
def main():
    type = 'news'  # ê²€ìƒ‰-ë‰´ìŠ¤ë¥¼ ì•Œë ¤ ì£¼ê¸° ìœ„í•œ ë³€ìˆ˜
    keyword = input('ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ') # ê²€ìƒ‰ì–´ ì…ë ¥
    cnt = 0
    jsonResult = [] # ë°˜í™˜ëœ json íŒŒì¼ì„ ì €ì¥í•  ë³€ìˆ˜
    
    jsonResponse = getNaverSearch(type, keyword, 1, 100)  #[CODE 2], start = 1, display = 100.
    
    if((jsonResponse != None) and (jsonResponse['display'] != 0)):
        for post in jsonResponse['items']:
            if ("n.news.naver.com" in post['link'] and cnt < 10): # ë§í¬ê°€ ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ì¼ ë•Œë§Œ ìŠ¤í¬ë˜í•‘
                cnt+= 1
                getPostData(post, jsonResult, cnt)   #[CODE 3]
    
    DataResult = [] # ë„¤ì´ë²„ì˜ ê¸°ì‚¬ ìŠ¤í¬ë˜í•‘ ë°ì´í„°ì™€ jsonResponseì— ìˆë˜ ë°ì´í„°ë“¤ì„ ë³‘í•©í•˜ì—¬ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    if ((jsonResult != None)):
        for post in jsonResult:
            if (cnt > 0):    
                getNewsData(post, DataResult)
                cnt -= 1;

if __name__ == '__main__':
    main()